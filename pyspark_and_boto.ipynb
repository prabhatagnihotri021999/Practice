{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ec7f72",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ee71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io \n",
    "import StringIO \n",
    "import botocore\n",
    "import fastparquet\n",
    "import pyarrow\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2718fdac",
   "metadata": {},
   "source": [
    "# Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_DEFAULT_REGION'] = ''\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = ''\n",
    "os.environ['AWS_SECRET_KEY'] = ''\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb772c",
   "metadata": {},
   "source": [
    "# Create boto-python client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1941929",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\n",
    "    service_name='', \n",
    "    region_name='',\n",
    "    aws_access_key_id='',\n",
    "    aws_secret_access_key=''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5930cb",
   "metadata": {},
   "source": [
    "# Read csv file from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = ''\n",
    "object_key = ''\n",
    "client = boto3.client('s3')\n",
    "csv_obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "body = csv_obj['Body']\n",
    "csv_string = body.read().decode('utf-8')\n",
    "df = pd.read_csv(StringIO(csv_string)) # tocreate csv file data into pandas data frame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217d5a2",
   "metadata": {},
   "source": [
    "# Read parquet file from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO()\n",
    "s3 = boto3.resource('s3')\n",
    "s3_object = s3.Object('1','2') # In 1 paste link name of s3 bucket and in 2 paste key of that parquet file\n",
    "s3_object.download_fileobj(buffer)\n",
    "table = pq.read_table(buffer)\n",
    "dff = table.to_pandas()\n",
    "dff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f9a79",
   "metadata": {},
   "source": [
    "# Download parquet file as csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6eab08",
   "metadata": {},
   "source": [
    "# Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39828cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a870460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Python Spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bda606",
   "metadata": {},
   "source": [
    "# Read csv file in Pyspark from our local "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eb0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parDF=spark.read.csv('')\n",
    "parDF.registerTempTable(\"parDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da395f1",
   "metadata": {},
   "source": [
    "# Create table having weekly money spend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e95991",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = '''(select account_no, round(date_format(to_date(date),'D')/7) as week, sum(amount) as money_spent \n",
    "        from pardf \n",
    "        group by week, account_no)''' \n",
    "t2 = spark.sql(t1) \n",
    "t2.toPandas().head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
